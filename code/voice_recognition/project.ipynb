{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "from scipy.signal import get_window\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from sklearn.mixture import GaussianMixture \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feartures Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MFCC Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization in order to get rid of amplification levels and differences between mics\n",
    "def normalize_audio(audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we devide the signal into short frames. Each audio frame will be the same size as the FFT\n",
    "def frame_audio(audio, FFT_size=2048, hop_size=10, sample_rate=44100):\n",
    "    audio = np.pad(audio, int(FFT_size / 2), mode='reflect')\n",
    "    frame_len = np.round(sample_rate * hop_size / 1000).astype(int)\n",
    "    frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "    frames = np.zeros((frame_num,FFT_size))\n",
    "    \n",
    "    for n in range(frame_num):\n",
    "        frames[n] = audio[n*frame_len:n*frame_len+FFT_size]\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_mel(freq):\n",
    "    return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
    "\n",
    "def met_to_freq(mels):\n",
    "    return 700.0 * (10.0**(mels / 2595.0) - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_points(fmin, fmax, mel_filter_num, FFT_size, sample_rate=44100):\n",
    "    fmin_mel = freq_to_mel(fmin)\n",
    "    fmax_mel = freq_to_mel(fmax)\n",
    "    \n",
    "    mels = np.linspace(fmin_mel, fmax_mel, num=mel_filter_num+2)\n",
    "    freqs = met_to_freq(mels)\n",
    "    \n",
    "    return np.floor((FFT_size + 1) / sample_rate * freqs).astype(int), freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(filter_points, FFT_size):\n",
    "    filters = np.zeros((len(filter_points)-2,int(FFT_size/2+1)))\n",
    "    \n",
    "    for n in range(len(filter_points)-2):\n",
    "        filters[n, filter_points[n] : filter_points[n + 1]] = np.linspace(0, 1, filter_points[n + 1] - filter_points[n])\n",
    "        filters[n, filter_points[n + 1] : filter_points[n + 2]] = np.linspace(1, 0, filter_points[n + 2] - filter_points[n + 1])\n",
    "    \n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct(dct_filter_num, filter_len):\n",
    "    basis = np.empty((dct_filter_num,filter_len))\n",
    "    basis[0, :] = 1.0 / np.sqrt(filter_len)\n",
    "    \n",
    "    samples = np.arange(1, 2 * filter_len, 2) * np.pi / (2.0 * filter_len)\n",
    "\n",
    "    for i in range(1, dct_filter_num):\n",
    "        basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / filter_len)\n",
    "        \n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCC(file_path):\n",
    "    hop_size = 15 #ms\n",
    "    FFT_size = 2048\n",
    "    audio , sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    audio = normalize_audio(audio)\n",
    "    audio_framed = frame_audio(audio, FFT_size=FFT_size, hop_size=hop_size, sample_rate=sample_rate)\n",
    "    window = get_window(\"hann\", FFT_size, fftbins=True)\n",
    "    audio_win = audio_framed * window\n",
    "    audio_winT = np.transpose(audio_win)\n",
    "    \n",
    "    audio_fft = np.empty((int(1 + FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F')\n",
    "\n",
    "    for n in range(audio_fft.shape[1]):\n",
    "        audio_fft[:, n] = scipy.fft.fft(audio_winT[:, n], axis=0)[:audio_fft.shape[0]]\n",
    "\n",
    "    audio_fft = np.transpose(audio_fft)\n",
    "\n",
    "    audio_power = np.square(np.abs(audio_fft))\n",
    "\n",
    "    freq_min = 0\n",
    "    freq_high = sample_rate / 2\n",
    "    mel_filter_num = 10\n",
    "    filter_points, mel_freqs = get_filter_points(freq_min, freq_high, mel_filter_num, FFT_size, sample_rate=44100)\n",
    "    filters = get_filters(filter_points, FFT_size)\n",
    "\n",
    "    enorm = 2.0 / (mel_freqs[2:mel_filter_num+2] - mel_freqs[:mel_filter_num])\n",
    "    filters *= enorm[:, np.newaxis]\n",
    "\n",
    "    audio_filtered = np.dot(filters, np.transpose(audio_power))\n",
    "    audio_log = 10.0 * np.log10(audio_filtered)\n",
    "\n",
    "    dct_filter_num = 40\n",
    "\n",
    "    dct_filters = dct(dct_filter_num, mel_filter_num)\n",
    "\n",
    "    cepstral_coefficents = np.dot(dct_filters, audio_log)\n",
    "    \n",
    "    # cepstral_coefficents = list(itertools.chain.from_iterable(cepstral_coefficents))\n",
    "\n",
    "    return cepstral_coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    audio , sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfcc_feature = mfcc.mfcc(audio,sample_rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    return mfcc_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresYahia = []\n",
    "directory = './files/3sec/'\n",
    "for audio in os.listdir('./files/3sec/'):\n",
    "    audio_path = directory + audio\n",
    "    featuresYahia1=np.vstack(extract_MFCC(audio_path))\n",
    "\n",
    "featuresAhmed = []\n",
    "directory = './files/Ahmed/'\n",
    "for audio in os.listdir('./files/Ahmed/'):\n",
    "    audio_path = directory + audio\n",
    "    featuresAhmed=np.vstack(extract_MFCC(audio_path))\n",
    "\n",
    "featuresMustafa = []\n",
    "directory = './files/Moustafa/'\n",
    "for audio in os.listdir('./files/Moustafa/'):\n",
    "    audio_path = directory + audio\n",
    "    featuresMustafa=np.vstack(extract_MFCC(audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# len(featuresYahia1[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = extract_MFCC('./files/Yahia_8.wav')\n",
    "\n",
    "# b = extract_MFCC('./files/nada.wav')\n",
    "# b = extract_MFCC('./files/test/ahmed_other_word.wav')\n",
    "b = extract_MFCC('./files/Ahmed/ahmed-2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-955.6925376405252\n",
      "-940.8208452901026\n",
      "-978.7532945484439\n"
     ]
    }
   ],
   "source": [
    "yahia_gmm = GaussianMixture(n_components = 1, max_iter = 90000, covariance_type='diag',n_init = 2)\n",
    "yahia_gmm.fit(featuresYahia1)\n",
    "\n",
    "ahmed_gmm = GaussianMixture(n_components = 1, max_iter = 90000, covariance_type='diag',n_init = 2)\n",
    "ahmed_gmm.fit(featuresAhmed)\n",
    "\n",
    "mostafa_gmm = GaussianMixture(n_components = 1, max_iter = 90000, covariance_type='diag',n_init = 2)\n",
    "mostafa_gmm.fit(featuresMustafa)\n",
    "\n",
    "scores_1 = np.array(ahmed_gmm.score(b))\n",
    "scores_2 = np.array(yahia_gmm.score(b))\n",
    "scores_3 = np.array(mostafa_gmm.score(b))\n",
    "print(scores_1.sum())\n",
    "print(scores_2.sum())\n",
    "print(scores_3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7536d7b229462f4296d4c0dae49c3bd6cd3990c783d6b9d88ce3c31a78605890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
