{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "import librosa\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  inf  nan  nan  nan  nan  nan  nan  nan\n",
      "  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_16240\\1444001817.py:88: RuntimeWarning: divide by zero encountered in log10\n",
      "  audio_log = 10.0 * np.log10(audio_filtered)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = './files/mostafa/'\n",
    "x, sample_rate = librosa.load('./files/mostafa/3.wav', res_type='kaiser_fast')\n",
    "sample_rate, audio = wavfile.read(TRAIN_PATH + \"3.wav\")\n",
    "mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "# Normalizing the audio \"dividing its values on the max value\"\n",
    "def normalize_audio(audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "# Calling the normalize function\n",
    "audio = normalize_audio(audio)  # 2D matrix (85322,2)\n",
    "\n",
    "# Dividing the audio into frames due to \"audio is not stationary\"\n",
    "def frame_audio(audio, FFT_size=2048, hop_size=512, sample_rate=44100):\n",
    "    # hop_size in ms\n",
    "    \n",
    "    # audio is padded which means that it has zero borders.\n",
    "    audio     = np.pad(audio, int(FFT_size / 2), mode='reflect')    # return => pad : ndarray Padded array of rank equal to array with shape increased according to pad_width\n",
    "    audio     = audio[:,0] # stereo to only one channel\n",
    "    frame_len = np.round(sample_rate * hop_size / 1000).astype(int) # return frame length\n",
    "    frame_num = int((len(audio) - FFT_size) / frame_len) + 1\n",
    "    frames    = np.zeros((frame_num, FFT_size))\n",
    "\n",
    "    for n in range(frame_num):\n",
    "        frames[n] = audio[n*frame_len : n*frame_len+FFT_size] #WARNING\n",
    "    \n",
    "    return frames\n",
    "\n",
    "hop_size = 512  # hop is the number of points intersected among frames   # if the hop size increased \"exp 2\", then the number of frames decrease\n",
    "FFT_size = 2048 # frame size\n",
    "\n",
    "audio_framed = frame_audio(audio, FFT_size=FFT_size, hop_size=hop_size, sample_rate=sample_rate)\n",
    "\n",
    "window = get_window(\"hann\", FFT_size, fftbins=True) # Create window, its size = frame size\n",
    "\n",
    "audio_win = audio_framed * window    # Multiply window by frame to make edges sync to zero\n",
    "\n",
    "audio_winT = np.transpose(audio_win) # Transpose the result\n",
    "\n",
    "audio_fft = np.empty((int(1 + FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F') # Getting Fast Fourier \n",
    "\n",
    "for n in range(audio_fft.shape[1]): \n",
    "    audio_fft[:, n] = fft.fft(audio_winT[:, n], axis=0)[:audio_fft.shape[0]] # Applyting fft to all frames\n",
    "\n",
    "audio_fft = np.transpose(audio_fft)        # Transpose the Fourier\n",
    "\n",
    "audio_power = np.square(np.abs(audio_fft)) # Calculating the signal power\n",
    "\n",
    "freq_min = 0\n",
    "freq_high = sample_rate / 2\n",
    "mel_filter_num = 10\n",
    "\n",
    "def freq_to_mel(freq):\n",
    "    return 2595.0 * np.log10(1.0 + freq / 700.0) # mel equation to convert from freq scale to mel scale\n",
    "\n",
    "def met_to_freq(mels):\n",
    "    return 700.0 * (10.0**(mels / 2595.0) - 1.0) # mel equation to convert from mel scale to freq scale\n",
    "\n",
    "# Creating bins\n",
    "def get_filter_points(fmin, fmax, mel_filter_num, FFT_size, sample_rate=44100): # getting filter points\n",
    "    fmin_mel = freq_to_mel(fmin)\n",
    "    fmax_mel = freq_to_mel(fmax)\n",
    "\n",
    "    mels = np.linspace(fmin_mel, fmax_mel, num=mel_filter_num+2) # created 12 mel banks\n",
    "    freqs = met_to_freq(mels) # convert these points back to freq scale \"center frequencies of the mel band\"\n",
    "    \n",
    "    return np.floor((FFT_size + 1) / sample_rate * freqs).astype(int), freqs # round bins to nearest freq bin to \n",
    "\n",
    "filter_points, mel_freqs = get_filter_points(freq_min, freq_high, mel_filter_num, FFT_size, sample_rate=44100)\n",
    "\n",
    "# Creating filters\n",
    "def get_filters(filter_points, FFT_size): # constructing triangle filters using filter points\n",
    "    filters = np.zeros((len(filter_points)-2,int(FFT_size/2+1)))\n",
    "    \n",
    "    for n in range(len(filter_points)-2):\n",
    "        filters[n, filter_points[n] : filter_points[n + 1]] = np.linspace(0, 1, filter_points[n + 1] - filter_points[n])\n",
    "        filters[n, filter_points[n + 1] : filter_points[n + 2]] = np.linspace(1, 0, filter_points[n + 2] - filter_points[n + 1])\n",
    "    \n",
    "    return filters\n",
    "\n",
    "filters = get_filters(filter_points, FFT_size)\n",
    "\n",
    "# taken from the librosa library\n",
    "enorm = 2.0 / (mel_freqs[2:mel_filter_num+2] - mel_freqs[:mel_filter_num])\n",
    "filters *= enorm[:, np.newaxis]\n",
    "\n",
    "audio_filtered = np.dot(filters, np.transpose(audio_power))\n",
    "audio_log = 10.0 * np.log10(audio_filtered)\n",
    "\n",
    "def dct(dct_filter_num, filter_len):\n",
    "    basis = np.empty((dct_filter_num,filter_len))\n",
    "    basis[0, :] = 1.0 / np.sqrt(filter_len)\n",
    "    \n",
    "    samples = np.arange(1, 2 * filter_len, 2) * np.pi / (2.0 * filter_len)\n",
    "\n",
    "    for i in range(1, dct_filter_num):\n",
    "        basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / filter_len)\n",
    "        \n",
    "    return basis\n",
    "\n",
    "dct_filter_num = 40\n",
    "\n",
    "dct_filters = dct(dct_filter_num, mel_filter_num)\n",
    "\n",
    "cepstral_coefficents = np.dot(dct_filters, audio_log)\n",
    "\n",
    "print(np.mean(cepstral_coefficents[:].T, axis=0))\n",
    "mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "# print(\"----------------------------\")\n",
    "# print(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "\n",
    "# zcr_scratch = np.array\n",
    "\n",
    "# x, sample_rate = librosa.load('./files/magdy/1.wav', res_type='kaiser_fast')\n",
    "\n",
    "# for index in range(0, len(x) - 1):\n",
    "#     zcr_scratch = zcr_scratch + (np.sign(x[index]) - np.sign(x[index + 1]) ) / 2\n",
    "\n",
    "# print(zcr_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrum import power_to_db, _spectrogram\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.fftpack\n",
    "\n",
    "def melspectrogram(*,y=None,sr=22050,S=None,n_fft=2048,hop_length=512,win_length=None,window=\"hann\",center=True,pad_mode=\"constant\",power=2.0,**kwargs,):\n",
    "\n",
    "    S, n_fft = _spectrogram(\n",
    "        y=y,\n",
    "        S=S,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        power=power,\n",
    "        win_length=win_length,\n",
    "        window=window,\n",
    "        center=center,\n",
    "        pad_mode=pad_mode,\n",
    "    )\n",
    "\n",
    "    # Build a Mel filter\n",
    "    mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
    "\n",
    "    return np.einsum(\"...ft,mf->...mt\", S, mel_basis, optimize=True)\n",
    "\n",
    "# -- Mel spectrogram and MFCCs -- #\n",
    "def mfcc(*, y=None, sr=22050, S=None, n_mfcc=20, dct_type=2, norm=\"ortho\", lifter=0, **kwargs):\n",
    "\n",
    "    if S is None:\n",
    "        # multichannel behavior may be different due to relative noise floor differences between channels\n",
    "        S = power_to_db(melspectrogram(y=y, sr=sr, **kwargs))\n",
    "\n",
    "    M = scipy.fftpack.dct(S, axis=-2, type=dct_type, norm=norm)[..., :n_mfcc, :]\n",
    "\n",
    "    if lifter > 0:\n",
    "        # shape lifter for broadcasting\n",
    "        LI = np.sin(np.pi * np.arange(1, 1 + n_mfcc, dtype=M.dtype) / lifter)\n",
    "        LI = util.expand_to(LI, ndim=S.ndim, axes=-2)\n",
    "\n",
    "        M *= 1 + (lifter / 2) * LI\n",
    "        return M\n",
    "    elif lifter == 0:\n",
    "        return M\n",
    "    else:\n",
    "        raise ParameterError(\n",
    "            \"MFCC lifter={} must be a non-negative number\".format(lifter)\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7536d7b229462f4296d4c0dae49c3bd6cd3990c783d6b9d88ce3c31a78605890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
